{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c5fcf9",
   "metadata": {},
   "source": [
    "# Using Tools\n",
    "-Define the tool (function) that we want to call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3fb727",
   "metadata": {},
   "source": [
    "# Step 1: Define model and tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "#Only for Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Initialize the OpenAI client for Ollama   \n",
    "# And add instructor wrapper for Pydantic validation\n",
    "#--------------------------------------------------------\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1/\", \n",
    "    api_key=\"\"\n",
    "    )\n",
    "\n",
    "client = instructor.patch(client)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Define the tool (function) that we want to call\n",
    "#----------------------------------------------------------\n",
    "def get_weather(latitude, longitude):\n",
    "    \"\"\"This is a publically available API that returns the weather for a given location.\"\"\"\n",
    "    response = requests.get(\n",
    "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n",
    "    )\n",
    "    data = response.json()\n",
    "    return data[\"current\"]\n",
    "\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Define the tool schema for the LLM\n",
    "#--------------------------------------------------------\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"latitude\": {\"type\": \"number\"},\n",
    "                    \"longitude\": {\"type\": \"number\"},\n",
    "                },\n",
    "                \"required\": [\"latitude\", \"longitude\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "            \"strict\": True,\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Define the response model for the LLM\n",
    "#--------------------------------------------------------\n",
    "class WeatherResponse(BaseModel):\n",
    "    temperature: float = Field(description=\"The current temperature in celsius for the given location.\")\n",
    "    response: str = Field(description=\"A natural language response to the user's question.\")\n",
    "\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Step 1: Call model with get_weather tool defined\n",
    "#--------------------------------------------------------\n",
    "model = \"llama3.1:8b\"\n",
    "messages=[        \n",
    "            {\"role\": \"system\",  \"content\": \"You are a helpful weather assistant.\"},\n",
    "            {\"role\": \"user\",    \"content\": \"What's the weather like in Tainan, Taiwan now ?\"},\n",
    "        ]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    messages=messages,     \n",
    "    temperature=0,\n",
    "    response_model= WeatherResponse   \n",
    "    )\n",
    "\n",
    "print(json.dumps(completion.model_dump(), indent=2))\n",
    "\n",
    "# No response_model= WeatherResponse \n",
    "completion2 = client.chat.completions.create(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    messages=messages,     \n",
    "    temperature=0, \n",
    "    )\n",
    "\n",
    "print(json.dumps(completion2.model_dump(), indent=2))\n",
    "\n",
    "\n",
    "# Or just the model response\n",
    "#print(completion.model_dump())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0add2eb",
   "metadata": {},
   "source": [
    "# Step 2: Execute get_weather function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e362fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Execute get_weather function\n",
    "for tool_call in completion2.choices[0].message.tool_calls:\n",
    "    # Extract the function name and arguments\n",
    "    name = tool_call.function.name    \n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    print(f\"Calling function {name} with args {args}\")\n",
    "    \n",
    "    messages.append(completion2.choices[0].message)\n",
    "    print(\"Messages so far:\", messages)\n",
    "    \n",
    "    # Call the function\n",
    "    result = None\n",
    "    if name == \"get_weather\":\n",
    "        result = get_weather(**args)\n",
    "        print(f\"Function call result: {result}\") \n",
    "                   \n",
    "        messages.append(\n",
    "            {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(result)}\n",
    "        )\n",
    "        print(\"Messages so far:\", messages)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d447d9",
   "metadata": {},
   "source": [
    "# Step 3: Supply result and call model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc5fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.5\n",
      "There has been a tool call. Today's weather in Tainan, Taiwan is mostly sunny with moderate temperatures around 28째C (82째F). The wind speed is relatively low at approximately 1.4 m/s (3.13 mph), indicating a calm environment.\n",
      "temperature=28.5 response=\"There has been a tool call. Today's weather in Tainan, Taiwan is mostly sunny with moderate temperatures around 28째C (82째F). The wind speed is relatively low at approximately 1.4 m/s (3.13 mph), indicating a calm environment.\"\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Supply result and call model again\n",
    "\n",
    "\n",
    "# Call the model again with the function result\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    response_format=WeatherResponse,\n",
    ")\n",
    "\n",
    "\n",
    "final_response = completion.choices[0].message.parsed\n",
    "print(final_response.temperature)\n",
    "print(final_response.response)\n",
    "print(final_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
