{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db0a7e9c",
   "metadata": {},
   "source": [
    "# Structured Output, 1-Use ollama.AsyncClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5acd91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Alpha Status Meeting\n",
      "2024-09-01\n",
      "['Alice', 'Bob', 'Charlie']\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import ollama\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "\n",
    "#Only for Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "            \n",
    "async def main():          \n",
    "         \n",
    "    OLLAMA_MODEL = 'llama3.1:8b'      \n",
    "    ollama_async_client = ollama.AsyncClient() \n",
    "    await ollama_async_client.pull(OLLAMA_MODEL)    \n",
    "                         \n",
    "    prompt = \"\"\"\n",
    "        Create a calendar event for a team meeting. The meeting is on 2024-09-01, is about 'Project Alpha Status', \n",
    "        and the participants are 'Alice', 'Bob', and 'Charlie'. Respond in JSON format. The JSON must contain the following keys exactly:\n",
    "            - name: (a string for the event title)\n",
    "            - date: (a string for the event date in YYYY-MM-DD format)\n",
    "            - participants: (a list of strings for the names of participants)\n",
    "            \"\"\"\n",
    "        \n",
    "    response = await ollama_async_client.chat(        \n",
    "                model=OLLAMA_MODEL, \n",
    "                messages=[{'role': 'user', 'content': prompt}],\n",
    "                format='json',\n",
    "                options={'temperature': 0.7},    # <-- Add the temperature parameter here                \n",
    "                # ===> This does not work yet in ollama.py\n",
    "                #output_model=CalendarEvent       \n",
    "            )\n",
    "          \n",
    "    #print(response['message']['content'])\n",
    "    try:            \n",
    "            response_content = response['message']['content']\n",
    "            data = json.loads(response_content)\n",
    "            \n",
    "            # ===> Validate and parse the JSON response into the CalendarEvent model\n",
    "            event = CalendarEvent.model_validate(data)\n",
    "            \n",
    "            print(event.name)\n",
    "            print(event.date)\n",
    "            print(event.participants)\n",
    "            \n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "            print(f\"Error parsing or validating JSON response: {e}\")\n",
    "            #print(f\"Raw response content: {response_content}\")\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # Run the main asynchronous function\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78c0d9",
   "metadata": {},
   "source": [
    "# Use Instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32045b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of client ===>  <class 'instructor.core.client.Instructor'>\n",
      "name='Project Alpha Status' date='2024-09-01' participants=['Alice', 'Bob', 'Charlie']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import json\n",
    "import ollama\n",
    "from pydantic import BaseModel, ValidationError\n",
    "import instructor\n",
    "\n",
    "#Only for Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "            \n",
    "            \n",
    "async def main():    \n",
    "    OLLAMA_MODEL = 'llama3.1:8b'      \n",
    "    ollama_async_client = ollama.AsyncClient() \n",
    "    await ollama_async_client.pull(OLLAMA_MODEL)    \n",
    "                         \n",
    "    prompt = \"\"\"\n",
    "        Create a calendar event for a team meeting. The meeting is on 2024-09-01, is about 'Project Alpha Status', \n",
    "        and the participants are 'Alice', 'Bob', and 'Charlie'. Respond in JSON format. The JSON must contain the following keys exactly:\n",
    "            - name: (a string for the event title)\n",
    "            - date: (a string for the event date in YYYY-MM-DD format)\n",
    "            - participants: (a list of strings for the names of participants)\n",
    "            \"\"\"\n",
    "    client = instructor.from_provider(\"ollama/llama3\")  # Ollama (local)\n",
    "    \n",
    "    print(\"type of client ===> \", type(client))\n",
    "    \n",
    "    response = client.chat.completions.create(        \n",
    "            model=OLLAMA_MODEL, \n",
    "            messages=[{'role': 'user', 'content': prompt}],                \n",
    "            temperature=0.7,    # <-- Add the temperature parameter here  \n",
    "            response_model=CalendarEvent       \n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(response)\n",
    "                        \n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "            print(f\"Error parsing or validating JSON response: {e}\")\n",
    "            #print(f\"Raw response content: {response_content}\")\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # Run the main asynchronous function\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203dd526",
   "metadata": {},
   "source": [
    "# Output, 2-Use OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa866fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-845', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here is a potential calendar event:\\n\\n**Event Title:** Project Alpha Meeting\\n**Date and Time:** September 1, 2024 (all day)\\n**Location:** [Insert location or virtual meeting details]\\n**Attendees:**\\n\\t* Alice\\n\\t* Bob\\n\\t* Charlie\\n**Description:** Project Alpha meeting to discuss progress and next steps.\\n\\nAlternatively, if you want a more detailed event:\\n\\n**Event Title:** Project Alpha Meeting\\n**Date and Time:** September 1, 2024 (10:00 AM - 12:00 PM)\\n**Location:** Conference Room A, [Insert location]\\n**Attendees:**\\n\\t* Alice\\n\\t* Bob\\n\\t* Charlie\\n**Description:** Project Alpha meeting to discuss progress and next steps. Agenda items include:\\n\\t+ Review of current project status\\n\\t+ Discussion of upcoming milestones\\n\\t+ Brainstorming for potential solutions to challenges', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1757219443, model='llama3.1:8b', object='chat.completion', service_tier=None, system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=185, prompt_tokens=41, total_tokens=226, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "#Only for Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "    \n",
    "            \n",
    "async def main():     \n",
    "    # Connect OpenAI client to local Ollama server\n",
    "    client = OpenAI(\n",
    "        base_url=\"http://localhost:11434/v1/\",\n",
    "        api_key=\"not-needed\"   # Ollama ignores it\n",
    "    )\n",
    "\n",
    "    # Add instructor wrapper for Pydantic validation\n",
    "    #client = instructor.patch(client)\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"llama3.1:8b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Create a calendar event for 2024-09-01 about Project Alpha with Alice, Bob, Charlie\"}\n",
    "            ],\n",
    "        temperature=0.3,\n",
    "        #response_model=CalendarEvent,  \n",
    "        #strict = True                 \n",
    "    )\n",
    "\n",
    "    #\n",
    "    #print(resp.model_dump_json(indent=2))\n",
    "    #print(resp.name)\n",
    "    #print(resp.date)\n",
    "    #print(resp.participants)\n",
    "    \n",
    "    #\n",
    "    #print(type(resp))  # <class '__main__.CalendarEvent'>\n",
    "    print(resp)  \n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # Run the main asynchronous function\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59560f62",
   "metadata": {},
   "source": [
    "# 3. Structured Output(Ollama), 2-Use OpenAI and instructor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee67262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Project Alpha\",\n",
      "  \"date\": \"2024-09-01\",\n",
      "  \"participants\": [\n",
      "    \"Alice\",\n",
      "    \"Bob\",\n",
      "    \"Charlie\"\n",
      "  ]\n",
      "}\n",
      "Project Alpha\n",
      "2024-09-01\n",
      "['Alice', 'Bob', 'Charlie']\n",
      "<class '__main__.CalendarEvent'>\n",
      "name='Project Alpha' date='2024-09-01' participants=['Alice', 'Bob', 'Charlie']\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "#Only for Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#--------------------------------------\n",
    "# pydantic BaseModel\n",
    "#--------------------------------------\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "    \n",
    "            \n",
    "async def main():     \n",
    "    # Connect OpenAI client to local Ollama server\n",
    "    client = OpenAI(\n",
    "        base_url=\"http://localhost:11434/v1/\",\n",
    "        api_key=\"not-needed\"   # Ollama ignores it\n",
    "    )\n",
    "\n",
    "    #  instructor, patch \n",
    "    client = instructor.patch(client)\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"llama3.1:8b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Create a calendar event for 2024-09-01 about Project Alpha with Alice, Bob, Charlie\"}\n",
    "            ],\n",
    "        temperature=0.3,\n",
    "        # Instructor and Patch\n",
    "        response_model=CalendarEvent,  \n",
    "        strict = True,                 \n",
    "    )\n",
    "\n",
    "    #\n",
    "    print(resp.model_dump_json(indent=2))\n",
    "    print(resp.name)\n",
    "    print(resp.date)\n",
    "    print(resp.participants)\n",
    "    \n",
    "    #\n",
    "    print(type(resp))  # <class '__main__.CalendarEvent'>\n",
    "    print(resp)  \n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # Run the main asynchronous function\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-312 (.venv-312)",
   "language": "python",
   "name": ".venv-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
