{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db0a7e9c",
   "metadata": {},
   "source": [
    "# Structured Output, 1-Use ollama.AsyncClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5acd91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import ollama\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "#Only for Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "            \n",
    "async def main():           \n",
    "    OLLAMA_MODEL = 'llama3.1:8b'      \n",
    "    ollama_async_client = ollama.AsyncClient()      \n",
    "    await ollama_async_client.pull(OLLAMA_MODEL)   \n",
    "              \n",
    "    prompt = \"\"\"\n",
    "        Create a calendar event for a team meeting. The meeting is on 2024-09-01, is about 'Project Alpha Status', \n",
    "        and the participants are 'Alice', 'Bob', and 'Charlie'. Respond in JSON format. The JSON must contain the following keys exactly:\n",
    "            - name: (a string for the event title)\n",
    "            - date: (a string for the event date in YYYY-MM-DD format)\n",
    "            - participants: (a list of strings for the names of participants)\n",
    "            \"\"\"\n",
    "             \n",
    "    response = await ollama_async_client.chat(        \n",
    "                model=OLLAMA_MODEL, \n",
    "                messages=[{'role': 'user', 'content': prompt}],\n",
    "                format='json',\n",
    "                options={'temperature': 0.7}    # <-- Add the temperature parameter here\n",
    "                \n",
    "                # ===> This does not work yet in ollama.py\n",
    "                #output_model=CalendarEvent     \n",
    "            )\n",
    "\n",
    "    #print(response['message']['content'])\n",
    "    try:\n",
    "            response_content = response['message']['content']\n",
    "            data = json.loads(response_content)\n",
    "            \n",
    "            # ===> Validate and parse the JSON response into the CalendarEvent model\n",
    "            event = CalendarEvent.model_validate(data)\n",
    "            print(event.name)\n",
    "            print(event.date)\n",
    "            print(event.participants)\n",
    "            \n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "            print(f\"Error parsing or validating JSON response: {e}\")\n",
    "            print(f\"Raw response content: {response_content}\")\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # Run the main asynchronous function\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203dd526",
   "metadata": {},
   "source": [
    "# Structured Output, 2-Use OpenAI and wrap by instructor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa866fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Project Alpha\",\n",
      "  \"date\": \"2024-09-01\",\n",
      "  \"participants\": [\n",
      "    \"Alice\",\n",
      "    \"Bob\",\n",
      "    \"Charlie\"\n",
      "  ]\n",
      "}\n",
      "Project Alpha\n",
      "2024-09-01\n",
      "['Alice', 'Bob', 'Charlie']\n",
      "<class '__main__.CalendarEvent'>\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "#Only for Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "    \n",
    "            \n",
    "async def main():     \n",
    "    # Connect OpenAI client to local Ollama server\n",
    "    client = OpenAI(\n",
    "        base_url=\"http://localhost:11434/v1/\",\n",
    "        api_key=\"not-needed\"   # Ollama ignores it\n",
    "    )\n",
    "\n",
    "    # Add instructor wrapper for Pydantic validation\n",
    "    client = instructor.patch(client)\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"llama3.1:8b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Create a calendar event for 2024-09-01 about Project Alpha with Alice, Bob, Charlie\"}\n",
    "            ],\n",
    "        response_model=CalendarEvent,   # <-- Pydantic enforcement here!\n",
    "        temperature=0.3                 # ðŸ”¥ controls randomness\n",
    "    )\n",
    "\n",
    "    print(resp.model_dump_json(indent=2))\n",
    "    print(resp.name)\n",
    "    print(resp.date)\n",
    "    print(resp.participants)\n",
    "    print(type(resp))  # <class '__main__.CalendarEvent'>\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # Run the main asynchronous function\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-312 (.venv-312)",
   "language": "python",
   "name": ".venv-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
