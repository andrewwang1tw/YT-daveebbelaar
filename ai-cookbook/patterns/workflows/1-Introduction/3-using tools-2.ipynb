{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c5fcf9",
   "metadata": {},
   "source": [
    "# Using Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74a9b5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'GetWeather', 'description': 'Correctly extracted `GetWeather` with all the required parameters with correct types', 'parameters': {'properties': {'latitude': {'description': 'Latitude of the location', 'title': 'Latitude', 'type': 'number'}, 'longitude': {'description': 'Longitude of the location', 'title': 'Longitude', 'type': 'number'}}, 'required': ['latitude', 'longitude'], 'type': 'object'}, 'strict': True}\n"
     ]
    }
   ],
   "source": [
    "import instructor\n",
    "import requests\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from instructor import OpenAISchema\n",
    "from openai import OpenAI\n",
    "\n",
    "#Only for Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Initialize the OpenAI client for Ollama \n",
    "#--------------------------------------------------------\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1/\", \n",
    "    api_key=\"\"\n",
    ")\n",
    "client = instructor.patch(client)\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Tool response model \n",
    "#--------------------------------------------------------\n",
    "class WeatherResponse(BaseModel):\n",
    "    temperature: float = Field(description=\"The current temperature in celsius for the given location.\")\n",
    "    response: str = Field(description=\"A natural language response to the user's question.\")\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Tool & OpenAISchema\n",
    "#----------------------------------------------------------\n",
    "class GetWeather(OpenAISchema):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location\")\n",
    "\n",
    "    def run(self) -> dict:\n",
    "        \"\"\"Fetch weather info from Open-Meteo\"\"\"\n",
    "        response = requests.get(\n",
    "            f\"https://api.open-meteo.com/v1/forecast\"\n",
    "            f\"?latitude={self.latitude}&longitude={self.longitude}\"\n",
    "            f\"&current=temperature_2m,wind_speed_10m\"\n",
    "        )\n",
    "        data = response.json()\n",
    "        return data[\"current\"]\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Tool schema\n",
    "#--------------------------------------------------------\n",
    "GetWeather.openai_schema[\"strict\"] = True\n",
    "#GetWeather.openai_schema[\"max_retries\"] = 3\n",
    "tools = [{\n",
    "    \"type\": \"function\", \n",
    "    \"function\":GetWeather.openai_schema\n",
    "}]\n",
    "\n",
    "print(GetWeather.openai_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0211be89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool ===> GetWeather with args: {'latitude': 22.98, 'longitude': 120.21}, \n",
      "message ===>  ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_frp1tcjq', function=Function(arguments='{\"latitude\":22.98,\"longitude\":120.21}', name='GetWeather'), type='function', index=0)])\n",
      "\n",
      "Tool Calling 結果 ===> {'time': '2025-09-07T04:15', 'interval': 900, 'temperature_2m': 31.5, 'wind_speed_10m': 20.3}\n"
     ]
    }
   ],
   "source": [
    "model=\"llama3.1:8b\"\n",
    "messages=[            \n",
    "    {\"role\": \"system\",  \"content\": \"You are a helpful weather assistant.\"},\n",
    "    {\"role\": \"user\",    \"content\": \"What's the weather like now in Tainan, Taiwan now ?\"},\n",
    "]\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# 這是 OpenAI API 官方標準的端點 ===> 用於創建聊天對話的補全 (chat completion)。\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# 1. 根據 messages 和 tools，模型決定是要直接生成文字回覆，還是要呼叫工具 (tool call)。\n",
    "#    當模型決定呼叫工具時，它的回覆會包含工具名稱和參數，但不會執行工具。\n",
    "#---------------------------------------------------------------------------------------------\n",
    "completion2 = client.chat.completions.create(\n",
    "    model=model,    \n",
    "    messages=messages,     \n",
    "    temperature=0, \n",
    "    tools=tools,      \n",
    ")\n",
    "#print(f\"\\nchat completion ===>\\n\", json.dumps(completion2.model_dump(), indent=2))   \n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "# Retries = 3 and async\n",
    "#-------------------------------------------------------------------\n",
    "import inspect\n",
    "import time\n",
    "import asyncio\n",
    "\n",
    "async def call_with_retry(fn, retries=3, delay=1):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            result = fn()\n",
    "            if inspect.isawaitable(result):\n",
    "                result = await result               \n",
    "                 \n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"[Retry] 第 {attempt+1} 次失敗: {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                # 若在 async context 中，使用 asyncio.sleep\n",
    "                if asyncio.get_event_loop().is_running():\n",
    "                    await asyncio.sleep(delay)\n",
    "                else:\n",
    "                    time.sleep(delay)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# 2. 如果 LLM 說要 Call Tool\n",
    "#----------------------------------------------------------------------------\n",
    "tool_calls = completion2.choices[0].message.tool_calls\n",
    "if tool_calls:  \n",
    "    for tool_call in tool_calls:\n",
    "        # 3. 取出 Tool 的 name 和 參數    \n",
    "        # 4. 把 LLM 回覆加入到 messages 列表中。使 messages 現在包含了使用者發問和 LLM 的回覆\n",
    "        name = tool_call.function.name    \n",
    "        args = json.loads(tool_call.function.arguments)        \n",
    "        messages.append(completion2.choices[0].message)    \n",
    "        print(f\"\\nTool ===> {name} with args: {args}, \\nmessage ===> \", completion2.choices[0].message)   \n",
    "          \n",
    "        # 5. Tool Calling\n",
    "        result = None\n",
    "        if name == \"GetWeather\":     \n",
    "            result = await call_with_retry(lambda: GetWeather(**args).run(), retries=3)    \n",
    "            messages.append(\n",
    "                {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(result)}\n",
    "            )  \n",
    "            print(f\"\\nTool Calling 結果 ===> {result}\")           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dbc5fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WeatherResponse Model 定義的 temperature ===>  31.5\n",
      "WeatherResponse Model 定義的 response ===>  Currently in Tainan, Taiwan it is 31.5°C (approximately 88.7°F) with a wind speed of about 20.3 km/h (12.6 mph). Please note that this information is accurate as of the provided timestamp (2025-09-07T04:15) and may have changed since then.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "# 6. 最後讓 LLM 根據工具回傳的內容，生成你想要的自然語言回應。\n",
    "#    而且回傳格式會符合你定義的 WeatherResponse Pydantic schema\n",
    "#----------------------------------------------------------------------------\n",
    "completion = client.chat.completions.parse(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    response_format=WeatherResponse,\n",
    ")\n",
    "\n",
    "final_response = completion.choices[0].message.parsed\n",
    "print(\"\\nWeatherResponse Model 定義的 temperature ===> \", final_response.temperature)\n",
    "print(\"WeatherResponse Model 定義的 response ===> \",final_response.response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-312 (.venv-312)",
   "language": "python",
   "name": ".venv-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
