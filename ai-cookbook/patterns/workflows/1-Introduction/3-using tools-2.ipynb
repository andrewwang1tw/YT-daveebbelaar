{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c5fcf9",
   "metadata": {},
   "source": [
    "# Using Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a9b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "import requests\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from instructor import OpenAISchema\n",
    "from openai import OpenAI\n",
    "\n",
    "#Only for Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Initialize the OpenAI client for Ollama   \n",
    "# And add instructor wrapper for Pydantic validation\n",
    "#--------------------------------------------------------\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1/\", \n",
    "    api_key=\"\"\n",
    ")\n",
    "client = instructor.patch(client)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Tool \n",
    "#----------------------------------------------------------\n",
    "class GetWeather(OpenAISchema):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location\")\n",
    "\n",
    "    def run(self) -> dict:\n",
    "        \"\"\"Fetch weather info from Open-Meteo\"\"\"\n",
    "        response = requests.get(\n",
    "            f\"https://api.open-meteo.com/v1/forecast\"\n",
    "            f\"?latitude={self.latitude}&longitude={self.longitude}\"\n",
    "            f\"&current=temperature_2m,wind_speed_10m\"\n",
    "        )\n",
    "        data = response.json()\n",
    "        return data[\"current\"]\n",
    "\n",
    "tool_schema = GetWeather.openai_schema\n",
    "tool_schema[\"strict\"] = True\n",
    "tools = [{\n",
    "    \"type\": \"function\", \n",
    "    \"function\":GetWeather.openai_schema\n",
    "}]\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Tool response model \n",
    "#--------------------------------------------------------\n",
    "class WeatherResponse(BaseModel):\n",
    "    temperature: float = Field(description=\"The current temperature in celsius for the given location.\")\n",
    "    response: str = Field(description=\"A natural language response to the user's question.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0211be89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "chat completion ===>\n",
      " {\n",
      "  \"id\": \"chatcmpl-288\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": null,\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_bq48apgg\",\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"latitude\\\":22.98,\\\"longitude\\\":120.21}\",\n",
      "              \"name\": \"GetWeather\"\n",
      "            },\n",
      "            \"type\": \"function\",\n",
      "            \"index\": 0\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1757145406,\n",
      "  \"model\": \"llama3.1:8b\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": null,\n",
      "  \"system_fingerprint\": \"fp_ollama\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 27,\n",
      "    \"prompt_tokens\": 203,\n",
      "    \"total_tokens\": 230,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": null,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": null\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Messages after create: ===>\n",
      " ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_bq48apgg', function=Function(arguments='{\"latitude\":22.98,\"longitude\":120.21}', name='GetWeather'), type='function', index=0)])\n",
      "\n",
      "Tool Calling 結果 ===>\n",
      " {'time': '2025-09-06T07:45', 'interval': 900, 'temperature_2m': 30.2, 'wind_speed_10m': 11.9}\n"
     ]
    }
   ],
   "source": [
    "model=\"llama3.1:8b\"\n",
    "messages=[            \n",
    "    {\"role\": \"system\",  \"content\": \"You are a helpful weather assistant.\"},\n",
    "    {\"role\": \"user\",    \"content\": \"What's the weather like now in Tainan, Taiwan now ?\"},\n",
    "]\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# 這是 OpenAI API 官方標準的端點 ===> 用於創建聊天對話的補全 (chat completion)。\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# 1. 根據 messages 和 tools，模型決定是要直接生成文字回覆，還是要呼叫工具 (tool call)。\n",
    "#    當模型決定呼叫工具時，它的回覆會包含工具名稱和參數，但不會執行工具。\n",
    "#---------------------------------------------------------------------------------------------\n",
    "completion2 = client.chat.completions.create(\n",
    "    model=model,    \n",
    "    messages=messages,     \n",
    "    temperature=0, \n",
    "    tools=tools,      \n",
    ")\n",
    "\n",
    "print(f\"\\nchat completion ===>\\n\", json.dumps(completion2.model_dump(), indent=2))   \n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# 2. 如果 LLM 說要 Call Tool\n",
    "#----------------------------------------------------------------------------\n",
    "tool_calls = completion2.choices[0].message.tool_calls\n",
    "if tool_calls:  \n",
    "    for tool_call in completion2.choices[0].message.tool_calls:\n",
    "        # 3. 取出 Tool 的 name 和 參數    \n",
    "        name = tool_call.function.name    \n",
    "        args = json.loads(tool_call.function.arguments)        \n",
    "        #print(f\"\\nCalling function: {name} with args: {args}\")               \n",
    "        #print(f\"\\nOriginal human message:\", messages)    \n",
    "            \n",
    "        # 4. 把模型的回覆加入到 messages 列表中。使 messages 現在包含了使用者發問和模型的回覆     \n",
    "        messages.append(completion2.choices[0].message)    \n",
    "        print(f\"\\nMessages after create: ===>\\n\", completion2.choices[0].message)     \n",
    "              \n",
    "        # 5. Tool Calling\n",
    "        result = None\n",
    "        if name == \"GetWeather\":\n",
    "            #result = get_weather(**args)               \n",
    "            result = GetWeather(**args).run()        \n",
    "            messages.append(\n",
    "                {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(result)}\n",
    "            )  \n",
    "            print(f\"\\nTool Calling 結果 ===>\\n {result}\")           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dbc5fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WeatherResponse Model 定義的 temperature ===>  30.2\n",
      "WeatherResponse Model 定義的 Response ===>  Now in Tainan, Taiwan, it is approximately 7:45 AM, with a temperature of around 30.2°C (86.36°F), and the wind speed is about 11.9 m/s (26.71 mph).\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "# 6. 最後讓 LLM 根據工具回傳的內容，生成你想要的自然語言回應。\n",
    "#    而且回傳格式會符合你定義的 WeatherResponse Pydantic schema\n",
    "#----------------------------------------------------------------------------\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    response_format=WeatherResponse,\n",
    ")\n",
    "\n",
    "final_response = completion.choices[0].message.parsed\n",
    "print(\"\\nWeatherResponse Model 定義的 temperature ===> \", final_response.temperature)\n",
    "print(\"WeatherResponse Model 定義的 Response ===> \",final_response.response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-312 (.venv-312)",
   "language": "python",
   "name": ".venv-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
